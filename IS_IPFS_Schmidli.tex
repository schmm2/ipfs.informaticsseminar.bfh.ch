\documentclass[a4paper,11pt, oneside]{report}

% Package import
\usepackage[a4paper,inner=3.5cm,outer=2.5cm]{geometry}
\usepackage[english,american]{babel}
\usepackage{fancyhdr}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{etoolbox}
\usepackage{fancyhdr}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage[xindy]{glossaries}
\usepackage{lastpage}
\usepackage{float}
\usepackage{fancyhdr}

\usepackage{listings}
\usepackage{xcolor}

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{F7F7F7}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\theoremstyle{definition}
\newtheorem{exmp}{Example}[subsection]

\makeglossaries

\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{1}


\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}

% clear default
\fancyhead{}
\fancyfoot{}


\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt} % optional
\fancyfoot[L]{Chapter: \nouppercase{\leftmark}}
\fancyfoot[R]{\thepage/\pageref{LastPage}}

% Redefine the plain page style, Chpater page
\fancypagestyle{plain}{%
  \fancyhf{}
  \renewcommand{\headrulewidth}{0pt} % optional
  \fancyfoot[R]{\thepage/\pageref{LastPage}}
}

\renewcommand{\chaptermark}[1]{\markboth{\MakeUppercase{#1}}{}}


% URL Line breaks
\makeatletter
\g@addto@macro{\UrlBreaks}{\UrlOrds}
\makeatother

\begin{document}


\pagestyle{empty} %Keine Kopf-/Fusszeilen auf den ersten Seiten.
\begin{titlepage}
\begin{center}

% Oberer Teil der Titelseite:
\includegraphics[width=0.08\textwidth]{img/bfh_logo.png}\\[1cm]    
\textsc{\LARGE Bern University of Applied Sciences}\\[1.5cm]
\textsc{\Large Informatics Seminar}\\[0.5cm]

% Title
\newcommand{\HRule}{\rule{\linewidth}{0.3mm}}
\HRule \\[0.4cm]
{\huge InterPlanetary File System}\\[0.3cm]
{\huge \bfseries  IPFS}
\HRule \\[1.5cm]

% Author und Lehrer
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Author:}\\
Martin \textsc{Schmidli}\\
\end{flushleft}
\end{minipage}
\hfill
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Teacher:} \\
Kai \textsc{Brünnler}
\end{flushright}
\end{minipage}
\vfill


% Unterer Teil der Seite
Bern, {\large \today}
\end{center}
\end{titlepage}
\pagestyle{fancy}

\tableofcontents


\chapter{Abstract}
IPFS (InterPlanetary Filesystem) is an open source protocol which can be used to run a distributed filesystem. IPFS was invented to tackle the drawbacks of the Internet and the Internet protocol suite we are using today.\\ \\
To understand why IPFS was invented, we first have to understand the issues we have today. This report will outline how IPFS works and what kind of issues it tries to resolve.

\chapter{Introduction}
IPFS stands for InterPlanetary Filesystem. It’s an open source Internet Protocol which can be used to run a distributed filesystem. The developers didn’t invent IPFS from scratch. In its core, IPFS takes advantage of existing ideas like Kademlia DHT, BitTorrent and Git. The main intention behind IPFS is to tackle the issues we are having in today's Inter- net/Web. In the eyes of the inventors, the protocol should be seen as an upgrade or even as a replacement of the existing technologies like HTTP. Global data distribution should be simplified and be implemented in the protocol itself rather than prescribe a separate distribution mechanism \cite{IPFSBasics}.\\ \\
All computers participating in an IPFS Network are called peers or nodes. IPFS is a peer 2 peer system, there are no central servers managing the network.

\section{Origin}
The Development of IPFS was started in 2014 by Juan Benet, former Stanford Student and founder of the company Protocol Labs. Protocol Labs and contributors of the Community are developing IPFS further \cite{LinkedIn}.

\section{Name}
The name was chosen as a tribute to J. C. R. Licklider, a computer scientist who came
up with an idea of an ”intergalactic network” of computers in 1962 \cite{Tribute}. He imagined a
global network of computers, able to talk to each other and exchange data. During his
time working at DARPA (Defense Advanced Research Projects Agency) he influenced
many people with his ideas. DARPA later started the ARPANET Project and laid the
foundation stone for today's Internet. Many important technologies, for example, TCP/IP
where invented or funded during this project  \cite{JCR}.

\newpage
\section{Project state}
As of 19.04.2017 the Specifications of the IPFS Protocol are still being developed and hasn't completed yet. The developers state, that the core parts of the specs have reached a reliable or stable state. No official RFC request have been submitted to the IETF. An Implementation of the Protocol, written in the programming language Go and some utilities have already been published. Implementation in other programming languages Javascript and Phyton are in developing \cite{specs}.\\ \\
Different sources state different facts how the system works. Many topics are still discussed intensively. This makes it very difficult to do a report about IPFS. The main data source of this report was the project's GitHub page and a white paper release by Juan Benett.

\section{Knowledgebase}
To understand the following chapters you should get yourself familiar with
\begin{itemize}
\item Hash functions
\item Distributed Hashtables
\item Bittorrent
\item Public-key cryptography 
\end{itemize}

\newpage
 

\chapter{Terms}
This chapter will get you familiar with some basic terms later used during this document.
\section{Content Adressing}
HTTP is addressing data with URLs. In IPFS the data is addressed by its contents hash.
\subsection{HTTP}
Data which is access by HTTP is addressed with its \textbf{hostname}, \textbf{port}, \textbf{path} and the \textbf{filename or search word} \cite{HTTPAdressing}. If the location of the file changes and no redirection was created, the link gets useless.
\begin{exmp} URL scheme used for HTTP
\noindent
\begin{center}
http : // hostname [ : port ] / path [ ? searchwords ]\\
https://raw.githubusercontent.com/github/gitignore/master/TeX.gitignore
\end{center}
\end{exmp}
\subsection{IPFS}
Data added to the IPFS network can be addressed by the hash of its content. The hash builds the link to data, document, picture... Every time we add data, the hash will be calculated. When the content of the file changes the hash/link will be changed as well.  The older content will still be accessible with the old hash value. The link and the data are immutable.
\begin{exmp} IPFS Link
\begin{center}
	/ipfs/QmbYzb3nScopAnfkoUpRWUFVv856uSWpSRc2KYM1FSBJxr
\end{center}
This scheme has been built similar than Unix filesystem paths. This design choice makes it possible to mount the IPFS filesystem directly into a Unix System. The IPFs filesystem can then be used by applications running on the Unix machine.
\end{exmp}


\section{Multiformats}
Multiformat is a collection of protocols/formats. They try to extend existing formats by adding self-describing components.  Two multiformats which are used in IPFS are Multihash and Multiaddr. This chapter will give you a short introduction to these formats. To understand these formats is necessary as they are used everywhere in the IPFS project.

\subsection{Hash functions - Multihash}
Multihash is a protocol/format  invented and maintained by the company Protocol Labs. Multihash defines a hash format, which is used in the IPFS project to encode Hashes. Every hash generated will be stored with two additional values; the Function code of the  hash function, which was used to generate this hash and the length of the hash.
\begin{center}
	Multihash Format = Hash Function Code + Hash Length + Hash
\end{center}
The hash function codes were set by the developers. For your own projects, you can easily implement your own code hash function reference list.\\[0.3cm]
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/multiformat_hashfunctionid.png}
\caption[Hashfunction code list]{Hashfunction code list}
\end{figure}
\noindent
Multihash should allow the software using IPFS to upgrade the hash functions more easily \cite{multihash}. For example, we hard coded SHA1 as a hash function into our program. If somebody would be able to break the SHA1 hash function we would have to replace the hash function. This would lead to longer hash values which might break our program. By using a more generic format the hash function can be switched very quickly.\\ \\
By default, IPFS Nodes are using the sha2-256 hash function. If a multihash has been generated it will be encoded by Base58 \cite{Encoding}.

\newpage
\begin{exmp} sha1
\begin{center}
	\includegraphics[width=\textwidth]{img/multihash_example.jpg}
\end{center}
\textbf{Functioncode:}\\
0x11, when we look up the Multihash Function Table we can find \textbf{sha1}. This hash was generated by the sha1 hash function.\\ \\
\textbf{Length:}\\
0x20 = 32, means 32 * 8 Bit = 256bit. The Hash is 256bit long.\\ \\
\textbf{Hash Digest:}\\ Hash values 
\end{exmp}

\newpage

\subsection{Peer Adressing - Multiaddr}
Multiaddr is used to represent common network adresses in a different way.
\begin{exmp}
Normal representation of a websocket url: 
\begin{center}
ws://1.2.3.4:5678\\
\end{center}
Multiaddr address:
\begin{center}
/ws/1.2.3.4/tcp/5678
\end{center}
\end{exmp}
\noindent
Like in Multihash were every hash function has a function code, in Multiaddr every protocol has a function code. \\
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{img/multiaddr.png}
\caption[Multiaddr code list]{Multiaddr code list}
\end{figure}
\noindent
With this change of the format and the substitution of the protocol string by a function code, the hole adress takes up less space in the binary format.
\begin{center}
<1 byte ws code><4 byte ipv4 addr><1 byte tcp code><2 byte tcp port>
\end{center}
\newpage

\chapter{Layer-Architecture}
IPFS is made of a stack of different software modules/libraries.\\ \\
\noindent
\begin{tabularx}{\textwidth}{XXXl}
\textbf{Software-Modul} &\textbf{Level} & \textbf{Layer} & \textbf{Function}\\ \hline
&7& Applications & Access the IPFS network \\ \hline
IPNS  &6 & Naming & creates immutable links \\ \hline
IPLD&5 & Merkle DAG & creates a relationship between data blocks \\ \hline
libp2p&4 & Exchange & exchange data blocks\\ 
&3 & Routing  & data \& peer lookup\\
&2 & Network  & connect to other nodes \\ 
&1 & Identities  & peer identity and verfification \\ \hline
\end{tabularx}\\[0.4cm]
This chapter will guide you from the bottom of the stack to the top to explain in detail how IPFS works.

\newpage

\section{Identities}
The identities module manages the node identity and the verification of other peers.\\ \\
During the initialization of a node, a 2048-bit RSA key pair (public, private) is generated. A hash function is used to generate the hash of the public key. This generated hash is then used as Peer ID \cite{PeerID}.
\begin{center}
Peer ID = multihash(public key)
\end{center}

\subsection{Trust}
There is no central certification authority in place which can be used to check if another peer can be trusted. The whole system has been designed to be self-verifying.\\[0.3cm]
\begin{exmp} Communication\\ \\
Peer A contacts another peer B. The Nodes exchange Node ID and Public Key.
Peer A generates the hash of the public key of peer B. If this generated hash doesn't match the NodeID of peer B the connection will be terminated.\\[0.3cm]
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{img/ipfs_peertrust_scenario_init.jpg}\\[0.2cm]
\caption[Node trust]{Node trust setup}
\end{figure}
\end{exmp}
\newpage
\begin{exmp}  Attack scenario\\ \\
Peer C tries to steal the identity of peer A. Peer C is using the public key and the Node ID from peer A. Peer B will establish a connection with peer C as the public key is valid and the Node ID matches. The sent data from B to C will be encrypted by Peer A's public key. As Peer C doesn't hold the private key, the data can't be decrypted.
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{img/ipfs_peertrust_scenario_attack.jpg}\\[0.2cm]
\caption[Node trust attack]{Node trust attack}
\end{figure}
\end{exmp}

\newpage
\section{libp2p - network, routing, exchange}
During the development of IPFS, the team learned how hard it was to run IPFS on many different devices with different requirements to the network \cite{libp2pissues}. It was impossible for them to provide one single protocol to work everywhere. They started to redefine the network, routeing and exchange layer and created an independent library call libp2p. This library is responsible for the network connectivity between nodes, the data lookup on the network and the data block exchange among them. In its core libp2p basically is a collection of p2p protocols and defines interfaces to use them. There are many different protocols supported which can be used depending on the situation of the node and its network. The protocols are implemented like blocks and can be combined dependent on the needs of the application developers.
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/libp2p-blocks.png}\\[0.2cm]
\caption[libp2p]{libp2p protocol collection}
\end{figure}
\noindent


\newpage
\subsection{Network}
The network layer establishes connections to other peers in the IPFS network.\\ \\
libp2p has been designed to be transport independent. It can run without IP stack for example on NDN \cite{ndn}, XIA \cite{xia} and Bluetooth\cite{libp2pnoip}.\\ \\
libp2p doesn't determine which kind of protocol should be used. For every layer, the developer is able to choose which protocols he would like to implement. With this choice, the developer decides how his application will work with other applications on the network.\\ \\
For example, if the developer decides to route the data over the TOR (the onion router) network the application will not be able to exchange data with nodes within the same network. It's a tradeoff, the application will be more secure, as it benefits of the anonymity of the TOR network but you will give up performance. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/libp2p-protocols.png}\\[0.2cm]
\caption[libp2p]{libp2p protocols.}
\end{figure}

\noindent
The network layer tries to make the node as available as possible, over the internet and in the local lan. 

\begin{exmp} Interfaces where my peers listens for a connection
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{img/ipfs-network-listen.png}\\[0.2cm]
\caption[IPFS listen interfaces]{IPFS listen on interfaces}
\end{figure}
\end{exmp}

\newpage

\subsection{Routing}
This Routing part of libp2p gives the IPFS node the ability to find the network address of other nodes and nodes which can serve specific data blocks.\\ \\
The peer routing module takes in a key (hash) and responds with one or more Peer Info Objects. The Peer Info contains the PeerID and its multiaddr addresses. With these informations, the other node can be contacted.\\ \\
The system is easily expandable. The protocols just need to fulfil the requirements of the Peer Routing interface. Currently, there are two Routing systems proposed and implemented.\\ \\
Every node in a routing system can contact all the participating peers. If data should be separated from the public IPFS network a separate instance of a routing system needs to be established. For example: create your own DHT.

\subsubsection{DHT}
A DSHT (distributed sloppy hash table) based on S/Kademlia and Coral can be used to store Key (Hash) Value (Peer ID) pairs. A DHT is a Hashtable which is distributed on all the participating IPFS peers. Every peer will be responsible for a percentage of all blocks added to IPFS. If a node leaves the IPFS network the responsibility of his part of the DHT will be forwarded to another node. \\ \\
If bigger data files > 256KB is uploaded to IPFS the file will be split up into smaller chunks. Every chunk  is added to the DHT and referenced to the node. For every chunk a new entry \textbf{Block Hash $\rightarrow$ Node ID} is added to the DHT.\\ \\
If a small file < 256KB is published, the data is directly stored on the DHT. A new entry \textbf{Block Hash $\rightarrow$ Data} is added to the DHT.\\ \\
This process of publishing data is called providing \cite{dht-provide}.\\ \\ 
If a node wants to find out where it can get the specific data blocks, it can use the DHT to determine the nodes which can serve those blocks.

\newpage
\begin{exmp}Add a large File to IPFS \\
In this example the folder structure ''ipfsdemo/pictures'' was added to the ipfs network. Inside the folder was placed a picture ''boys\_icefield.png''. The size of the picture is around 4.5MB. The file was split up inside smaller chunks.
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/ipfs-object-example.png}
\caption[Add big data]{Add a big file}
\end{figure}
\end{exmp}

\subsubsection{mDNS}
Uses the mDns protocol to check if a node in the local network holds a specific key.


\newpage
\section{Exchange - Bitswap}
Many exchange protocols can be used with IPFS, for example, FTP, HTTP, BitTorrent or Bitswap.\\ \\
Bitswap is a BitTorrent-inspired software module used to exchange data blocks between the nodes of the IPFS network. When a user requests a piece of data the specific blocks are added to the nodes ''want\_list'' list. Bitswap contacts other peers which own the data according to the Routing system (example. DHT) and sent them the ''want\_list''. Peers keep track of the blocks which they own by putting them into their ''have\_list'. If the receiver has blocks which another node requested, he will send the blocks back to the requester. 'When the blocks arrive, the requester will immediately send out a ''Cancel' signal. Other nodes will stop sending those blocks. After the blocks arrived the requester move those blocks from the want\_list to the have\_list  \cite{bitswap}.

\subsection{Exchange Strategies}
When a bitswap node requests data (Peer A), the other nodes (Peer B) will only send the requested data if they receive blocks in return. Most of the time Nodes store very different data and a number of blocks which they could offer in return is very limited. Sometimes Node doesn't own any data the other node is needing. This puts the requesting node (Node A) in a bad position as it has nothing he could offer in exchange. To resolve the situation, Node A will start to download the data Node B has on its want\_list  after all his own data requests are completed.  The own needs have a higher priority.\\ \\

\newpage
\begin{exmp}
Let's make a short example of how this strategy works.\\ 
We have 3 Nodes, A, B and C. Node A wants blocks of a ''music file'' but currently the Node doesn't store any data. Node B want's blocks of a ''science paper'' file and owns blocks of the ''music file''$\rightarrow$ Node A has no blocks which Node B actually needs.
\begin{center}
\includegraphics[width=0.7\textwidth]{img/ipfs_bitswap_noblocks.png}\\[0.3cm] 
\end{center}
After Peer A got all the music blocks he wanted, he will start to look for science paper blocks.
\end{exmp}

\subsection{Ledger}
Bitswap nodes keep track of the amount of data they send and received to other nodes in a digital ledger. We speak of credit or debt between the nodes. It's an indicator of the trust and the connection between two nodes. When a new connection is established, the nodes exchange their ledger. If the ledger data doesn't match, for example, if one of the nodes maliciously changed the data, the ledger and the connection will be resetet. Depending on the Bitswap strategy good connections between nodes, which already exchange a lot of data could be preferred. Nodes with a high debt could be neglected.

\newpage
\subsubsection{Automatical Download Problematic}
This exchange mechanism leads to data download even if the node doesn't actually need the data by itself. The data are cached and increase the availability of the blocks. This strategy is not yet implemented in bitswap. Today's implementation is syncing blocks without any conditions and doesn't fulfil the defined protocol specifications.\\ \\ 
There are ongoing discussions if this feature should be enabled by default or if there should be a config option to enable it \cite{bitswapstrategy}. If this feature is enabled by default, IPFS nodes would download data without any knowledge of the user. This would lead to an extensive usage of the local storage and could lead to legal problems. To avoid the legal problematic, there needs to be a system in place to avoid the download of Copyright Protected Data and to implement Digital Right Management (DRM). If and how this will be implemented is currently discussed in the community \cite{copyright}. Some possible approaches which are considered are 
\begin{itemize}
\item White \& Blacklist of certain blocks and objects\\ Users can enable filters which kind of content they want to download
\item Public trusted list of Copyright Protected content. \\ Prohibits the sharing of files on this list
\end{itemize}


\subsection{Data Availabiliy}
In today's implementation of IPFS, data is not actively distributed in the IPFS Network. If a node requests data, it will be downloaded and therefore replicated. There is no higher instance which is controlling how many times a specific data block is physically stored somewhere. Example; If one data block is added from Node A to the IPFS network and this node goes down, the data is no longer available.\\ \\ The developers try to solve this problem by designing a new software which is running on top of IPFS called IPFS-Cluster. The IPFS-Cluster Service will be running on the IPFS Node and makes sure, that data remains available. To cluster data, it will be ''pinned'' to a Node. Pinned data will not be removed localy if its running out of disk space. \\ \\
Data will be replicated/pinned among IPFS-Cluster nodes according to a predefined replication factor. Example; Replication factor 2, data us store on 2 Nodes. If a node with pinned data goes down, the data automatically is replicated to other cluster nodes.

\subsection{Difference to Bittorrent}

Bittorrent nodes can only request blocks from one torrent. Data blocks are not shared among torrents.


\newpage

\section{IPLD - Merkle DAG}
IPLD stands for Inter Planetary Linked Data. \\ 
The Merkle DAG which is part of IPLD gives a structure to the loose datablocks in the Routing System.\\ \\
IPLD defines
\begin{itemize}
\item Merkle directed acyclic graph\\ Used to create a relationship between the IPFS objects added to the Routingsystem for example DHT. 
\item Merkle-Links \\ Edges /links  between the objects of the DAG
\item Merkle-Paths \\ Unix-like path for traversing through the Merkle DAG
\item IPLD Data Model \\ Defines the data structure of the DAG objects, based on the JSON format
\end{itemize}

\subsection{Merkle DAG \& Merkle Links}
A Merkle DAG is a Directed Acyclic Graph where the objects are connected with merke-links. The Merkel DAG has the following features:
\begin{itemize}
\item No circle is allowed
\item Content is adressed by hashes $\rightarrow$  merkle-link\\ \\
Example:  /ipfs/QmKLTg7BZ ... 63JtDuvs2k\\ \\
Using merkle-links provides some advantages
\begin{itemize}
\item Accessed data can be verified/integrity checked by the hash.  
\item Data structures can't be modified as a change results in a new hash.
\end{itemize}
% \item When data is added to the graph it is automatically verified with the contents hash
\item Objects of data will be stored only once in the DAG. If data is added twice it will be reference by its hash $\rightarrow$ Automatic deduplication
\end{itemize}
The Merkle DAG Datastructure is different than a Merkle Tree. The Merkle DAG doesnt need to be balanced, the added data is automatically deduplicated and all nodes can contain data whereas in a Merkle tree only leaf nodes can contain data.

\newpage

\subsection{IPLD Data objects}
IPLD defines a basic datamodel based on JSON. The objects can be structured by the developer. This makes the DAG very flexibel. Various objects can be modelled to create complex datastructures.

\subsubsection{Merkle Links}
A merkle-link object contains of a key ''/'' which defines a link to another object and the actual link value. The link value can be a multihash or the absolut path with the ''/ips'' präfix. 
\begin{lstlisting}[language=json]
{ "/" : "/ipfs/QmKLTg7BZ ... 63JtDuvs2k" }
\end{lstlisting}

\subsubsection{Objects}
IPLD objects are basic JSON objects. They can be linked with merkle-links.
\begin{lstlisting}[language=json]
{ "name": "Martin Schmidlli" }
\end{lstlisting}

\begin{exmp} Example of linked objects
\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{img/ipld-example.png}\\[0.2cm]
\caption[IPLD linked objects]{IPLD linked objects}
\end{figure}
\end{exmp}

\newpage
\begin{exmp}{Add small Files <= 256kB}\\ \\ 
If the added data is smaller than 256kB, it's is stored directly into the DAG Object.
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{img/ipfs-fileblocks-small.png}
\caption[Small Object]{Small Object <= 256kB}
\end{figure}
\end{exmp}

\begin{exmp}{Add large Files > 256kB}\\ \\
If we add a file bigger than 256kB, the file will be split up into blocks. The generated hash will be the root node in the DAG. This root node will contain merkle-links to the subblocks/objects. The data segment is used to declare that this object represents a big file.\\ \\
If a node requests a block, this block can come from any node owning one of these blocks even if it's not from the same ''file'' \cite{fileblock}. Multiple IPFS objects can share blocks. As IPFS is addressed by hash, the actual data block is stored once.\cite{fileblock2}. \\[0.3cm]
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/ipfs-fileblocks-big.png}
\caption[Big Object \& Blocks]{Abstract visualization how blocks are handeled}
\end{figure}
\end{exmp}

\newpage
\subsection{Merkle Paths}
This is our basic object at the link /ipfs/QmKLTg7BZ ... 63JtDuvs2k\\
\begin{lstlisting}[language=json]
{ level1 : {
	level2: "Hello World"
}}
\end{lstlisting}
We can use merkle paths to reference to values or other object relative to the root.
\begin{center}
/ipfs/QmKLTg7BZ ... 63JtDuvs2k/level1/level2
\end{center}
We can traverse through the DAG Object /ipfs/QmKLTg7BZ ... 63JtDuvs2k like in a unix filesystem and access values of level2.
\begin{exmp} ipld cat
\begin{lstlisting}[language=json]
> ipld cat --json QmKLTg7BZ ... 63JtDuvs2k/level1/level2
"Hello World"
\end{lstlisting}
\end{exmp}


\subsection{Encryption}
Built-in file level encryption is one of the many missing features in IPFS today. The feature is listed in the IPFS whitepaper and will be added in a later release of the protocol. \cite{Encryption}. Data added to the IPFS network will automatically be encrypted. If private data is added to the ''public'' IPFS network, the developers recommend to encrypt it manually \cite{EncryptionManual}.


\newpage
\subsection{Complex Datastructures}
The basic DAG objects can be used to build more advanced data structures. Till today there are many implementations already developed:
\begin{itemize}
\item git
\item Zcash (crypto currency)
\item Bitcoin /crypto currency)
\item Ethereum
\item Unix Filesystem
\end{itemize}

\begin{exmp}IPFS Git commit message
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/dag-object-gitcommit.png}
\caption[DAG Objects commit]{DAG Objects - Git commit}
\end{figure}
\end{exmp}
\begin{exmp}IPFS Bitcoin block
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/dag-object-blockchain.png}
\caption[DAG Bitcoin block]{DAG Objects - Bitcoin block}
\end{figure}
\end{exmp}

\newpage
\section{State Mutability - IPNS}
All the data added to the IPFS Network is immutable. The data can't be changed anymore. New content generates new data and therefor a new hash key. If you change your data, peoble with the old hask key (link) will always be directed to the old version of the data. To solve this issue, the developers created the InterPlanatery Naming System (IPNS). IPNS creates self certifing mazieres links, invented by David Mazières, to create a reference to the newest content.
\begin{exmp}{Mazieres Links}\\
If we add data to ipfs an ipfs link gets created
\begin{center}
	/ipfs/QmU224/
\end{center}
A public / private keypair is needed to create one IPNS link.  The hash of the public key will be used to generate an IPNS link. If we resolve this IPNS link it should give us back the newest content, in this case: /ipfs/QmU224/
\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{img/ipns-1.png}
\caption[IPNS Step 1]{IPNS - Step 1}
\end{figure}
\newpage
\noindent
1.) To make this resolving process authenticated, the private key is used to sign a pointer object. The pointer object creates a link between the Public Key and the content. Three values are stored within this pointer object: The value (target hash), the key (public key hash) and a signature.\\
The pointer is another object in the IPFS Universe called IPRS Record. IPRS Records are stored on the Merkle DAG and can be used for authentication purposes.
\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{img/ipns-2.png}
\caption[IPNS Step 2]{IPNS - Step 2}
\end{figure}
\noindent
2.) Peer X wants to resolv the IPNS link\\
3.) Gets the public key\\
4.) The peer will look for a pointer record in the DAG with the specific hash of the public key. \\
5.) The signature will be verified with the public key\\
6.) The peer will find the target hash value. This value will then be used to build the final ipfs link. \\ \\
If the content should be updated, only the target hash of the pointer needs to be changed. The ipns link stays the same.


\end{exmp}

\newpage
\subsection{DNS Links}
So far we created a static link to the content we want to present to the world. The systems works, but those ipns links are not very user friendly. We can use the existing DNS System to create user friendly links and map them to our IPNS links.\\
\begin{exmp} Map DNS to IPNS\\
We can add a TXT Record to the DNS Zone of our domain example: ipfs.io \cite{DNS}
\begin{center}
	dnslink="/ipns/QmWGb7PZmLb1TwsMkE1b8jVK4LGceMYMsWaSmviSucWPGG"
\end{center}
If we enter /ipns/ipfs.io the ipfs client will resolv the DNS TXT  entry and fetch the data from the ipns link above.
\end{exmp}

\chapter{Goals of IPFS}
The developers of IPFS  state: The Internet/Web of today has many issues.  The existing protocols we have today, have some major design issues or are not good enouth anymore to satisfy the needs of todays Web and his Users \cite{TodaysProblems}. In this chapter I will list the main problems the developers and the community sees and try to analyze how IPFS could solve them.

\section{Offline functionality}
Imagine you are sitting with your colleagues at work. You all work together on a document. You are using a WebApplication to collaborate with each other. Suddenly the internet connection is lost. You are all sitting in the same local network but you are unable to share your version of the document with the others. All the data needs to be synced with the backbone service for example Google Docs. and then down again to the other clients / your colleagues. The Applications should be able to talk to each other and shouldn't be dependant of a service somewhere in the internet.\\ \\
The library libp2p which is integrated in IPFS, enables peers and their content to be detectet without any backbone service. The ipfs nodes can detect who owns which kind of data and request them for example by using mDNS. Static Webapplications can be served directly through ipfs. If new data is added to IPFS through the Applikation it will be available for other users aswell.

\section{Enhanced Protocol}
The most used Protocol from the Internet Protocol Suite by far is HTTP. It follows the Server-Client communication model. The Client establishes a connection to one server, sends requests and get responses back from the server. Even if there are load balancing mechanisms in place it will be served by the by one host only.\\[0.3cm]
The alternative communication model would be Peer to Peer short. p2p. The Clients establishes a connection to mutlible ''peers'' which will serve the requested data. Every peer will deliver a fraction of the data. Those data ''pieces'' will be downloaded simultainously.\\ \\
IPFS establishes a peer 2 peer network. Data can be simultaniously downloaded from different sources. This ''feature'' makes IPFS more reliable against DDoS attacks because the data is distributed all around the world.

\section{Permenancy}
I guess every person which used an Internet Browser before has seen a message like ''Error 404'' or ''Site not found''.
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{img/github-404.png}
\caption[Github 404 Error Page]{Github 404 Error Page}
\end{figure}
\noindent
The specific content you tried to reach has been deletet or has been moved by the sites provider. All the links provided are now useless. Every day content gets moved around or is deleted forever. Sometimes its just a silly picture of a cat but mostly its data somebody actually would have needed.\\[0.3cm]
Nevertheless there are several companies already trying to solve this issue by archiving all the data available on the internet. The most well known would be ''Internet Archive'' with its ''Wayback Machine'' Webapplikation. They are using web crawlers to get the data and store them. The User is able to use theWayback Machine to view the webpage back then when the Internet Archive made a snapshot of it \cite{InternetArchive}. By October 2016 they managed to archive 273 billion webpages from over 361 million websites, which resulted in a data size of 15 Petabytes (15'000 Terabytes) \cite{InternetArchiveCount}.\\ \\
All content added to IPFS is hashed and added permanent to the newtork. Once the IPFS cluster feature has been finialised the network will make sure the data stays online. The data can never be removed again as long as nodes are connected to the network serving this specific content. If some nodes break down the data get's rereplicated and stays available.


\section{Decentralization}
Big data hosting companies like Google or Amazon own datacenters worldwide. Developer can buy the service from them to cluster their application data  and distrbute it all over the world. This ensures the availability of your Application even in case of a datacenter outage caused by a natural catastrophe or other technical issues. Those incidents aren't fictions and cost millions if they happen. Latest example, 28.02.2107 a site of the Amazon S3 System located in Northern Virginia gots unavailable. Thousands of webpages and webapplications stopped working. A Amazon technican wantet to remove a small subset of servers. He entered the command wrong and more servers than planned were removed. This led to an 4h outage of the hole Site \cite{AWSOutage}. Estimated cost 150 Million US Dollar \cite{AWSOutageCost}.\\\\
Clustering of data is not standard today. To make your data highly available is cost intensive. To achieve the same level of high availability cost effective without any kind of big service provider like Google is near impossible.\\\\
A second group of big data handlers are the so called CDNs. These Content Delivery Networks host data worldwide and act as a proxy for data requests. Services of these providers are used to bring content closer to the customers to reduce latency and download time.\\ \\
Data on the IPFS system is ment to be permanent.  Once added to the network the IPFS cluster service will distrubute the data over multible nodes\\ \\
Close peers which can serve the blocks are prefered. The overall latency is reduced and the data is downloaded faster. The experience for the user is much more pleasant. For us living in a country with good internet download speed this feature will not change much. For other countries, in particular developing countries, it's a big deal.

\section{Security}
Todays data connections are secured. For exmaple by TLS. The data itself stored on the local machine is not encrypted. Files located at a data provider are encrypted but mostly the companies has the corresponding keys to them. Data can get monetized and missued by others.\\ \\ 
IPFSs way around this is to encrypt the data not the connection. All data added to the ipfs network will get encrypted and will be only accessible bye the user himself. This feature is yet to be developed \cite{Encryption}.


\section{Privacy / Consumer Protection}
In these days one of the main concerns of social media platforms are privacy issues and hate messages. Those companies, for example Facebook and Twitter, are facing huge fines in several countries because goverments think they don't do enouth to protect their users. \cite{HateSpeech}. Content shared with a service in the internet, mostly stayes in the internet as its rapidly shared and distributed. If it's out there it's out there forerver. The content itself is hard to locate and remove. The data is adressed with links. The links or URL changes from hoster to hoster. If the affacted user tries to notify the hoster of the data, for example a picture with the intetion to damage the users reputation, it might alread be hosted by several other platforms.\\ \\
Since all data in IPFS is adressed by a hash, content can be blocked entirely. After a further check through an engine or a authority the hash can get blocked. This method has some downsides
\begin{itemize} 
\item With a slight change at the data, example a pixel in a picture, it would get a new hash and can get uploaded again.
\item Who can be trusted, who should be able to block those hashes
\end{itemize}
So far the team created a feature called blacklist. Content added to this list can't be downloaded. The lists are maintained by the IPFS team. If the user want to follow this list is his decision no list are enforced.

\newpage
\chapter{Today}

\section{Usage}
\subsection{Webhosting}
Static Webpages can be hosted easily on IPFS as they contain only static files like .css or .html.
Accordning to Juan Benet more than 100'000 webpages have been uploaded to IPFS \cite{ipfs-usage-web}.
\section{Software \& Private Cloud}
The IPFS protool has been bundled with the popular software FreeNas. Free NAS turns every computer into a NAS (Network attached Storage) \cite{freenas}. By leberaging the IPFS network the data of the NAS can be shared and distributed.

\subsection{Archive}
The developers of IPFS startet a new project to bring the content of Wikipedia on IPFS. This project was started due the recent blockade of the Wikipedia Website in Turkey on the 29.04.2017 \cite{turkeyblock}.

\subsection{Blockchain}
In the last years the blockchain technology gain alot of popularity. More and more projects have been introduced. Some of the well knowns are Bitcoin and Ethereum. Ethereum is a plattform to run applications, so called DAPPs, decentralized. One Example of DAPPs are Smart Contratcs. A Smart contratc is a piece of software which stores some rules for negotiating the terms of a contract. If the rules are fullfilled, the programm automatically executes the the agreed terms \cite{ether}. The blockchain is the wrong place to store big data \cite{blockchain-data}. Some companies discovered IPFS to outsoruce tha data. The data is placed on the IPFS Network and only the hash  / link is stored in th blockchain.

\section{Competitors}
During the last years the dev team created a very powerful yet easy to understand protocol which could have  massive impact of how we work today with the internet. Nevertheless Protocol Labs aren't the first to come up with such an idea.
There are other companies like Maidsafe \cite{Maidsafe} or SIA  \cite{sia} trying to reinvent the web. They have a similar goal, us the unused disk capacity of a computer, decentralize and secure the data. In my opinion, IPFS takes it one step further by enabling developers to model alot of different data structures like Git filesystems or entire blockchains. The other companies are more focused on private clouds. IPFS, compared to maidsafe, lacks alot of features like built-in encryption and anonymity. This is and will be possible with IPFS aswell, however IPFS is still a young protocol and the features have yet to be developed.\\ \\
Like the competition did with SIA and Maidsafe, Protocol Labs is planning monetazie IPFS. The new technology is called Filecoin. It will allow users to offer their diskspace on their computer / server to the IPFS network and as a reward they will gain Filecoin. Filecoin is an Altcoin and can then be traded to Bitcoin and from there to ''real'' money like US Dollar. If the user caches more data means helpes to make conent available, he will receive more coins. This monetization should attract new user to IPFS and increase the available storage space wolrdwide.

\section{Future}
It's hard to determine the future of IPFS.  IPFS has no big spread. The protocol is still in the beta stage. Alot of big companies like the Wikimedia foundation  are interessed to use it.  Till the protocol doesn't reach a more stable stage / first realese  it will not be used in big software projects.\\



\begin{thebibliography}{1}

\bibitem{IPFSBasics} \url{https://github.com/ipfs/ipfs}, 24.07.2017
\bibitem{LinkedIn} \url{https://www.linkedin.com/in/jbenetcs/}, 28.04.2017
\bibitem{Tribute} \url{https://www.youtube.com/watch?v=HUVmypx9HGI} 4:30, 22.04.2017
\bibitem{JCR} \url{http://www.internetsociety.org/internet/what-internet/history-internet/brief-history-internet}, 22.04.2017
\bibitem{specs} \url{https://github.com/ipfs/specs}, 29.04.2017

\bibitem{TodaysProblems} \url{https://ipfs.io/}, Sector: The web of tomorrow needs IPFS today, 22.04.2017

\bibitem{InternetArchive} \url{https://en.wikipedia.org/wiki/Internet_Archive}, 22.04.2017
\bibitem{InternetArchiveCount} \url{https://blog.archive.org/2016/10/23/defining-web-pages-web-sites-and-web-captures}, 22.04.2017
\bibitem{AWSOutage} \url{https://aws.amazon.com/message/41926/}, 23.04.2017
\bibitem{AWSOutageCost} \url{http://www.npr.org/sections/thetwo-way/2017/03/03/518322734/amazon-and-the-150-million-typo}, 23.04.2017
\bibitem{HateSpeech} \url{https://www.nytimes.com/2017/03/14/technology/germany-hate-speech-facebook-tech.html?_r=0}, 23.04.2017
\bibitem{HTTPAdressing} \url{https://www.w3.org/Addressing/HTTPAddressing.html}, 23.04.2017 
\bibitem{PeerID}\url{https://github.com/ipfs/faq/issues/238}, 24.04.2017
\bibitem{hasfunction} \url{https://github.com/ipfs/faq/issues/22}, 30.04.2017
\bibitem{multihash} \url{https://github.com/jbenet/random-ideas/issues/1}, 24.04.2017
\bibitem{Encoding} \url{https://github.com/ipfs/faq/issues/22}, 30.04.2017
\bibitem{Encryption} \url{https://github.com/ipfs/faq/issues/116}, 30.04.2017
\bibitem{EncryptionManual} \url{https://github.com/ipfs/faq/issues/4}, 30.04.2017
\bibitem{bitswap} \url{https://github.com/ipfs/specs/tree/master/bitswap}, 29.04.2017
\bibitem{fileblock} \url{https://github.com/ipfs/examples/tree/master/examples/data}, 29.04.2017
\bibitem{fileblock2} \url{https://medium.com/@ConsenSys/an-introduction-to-ipfs-9bba4860abd0}, 29.04.2017
\bibitem{bitswapstrategy} \url{https://github.com/ipfs/faq/issues/47}, Q: but bitswap says..., 29.04.2017
\bibitem{Routing} \url{https://github.com/ipfs/faq/issues/48}, 29.04.2017
\bibitem{copyright}\url{https://www.reddit.com/r/ipfs/comments/3m351b/discussion_permanent_content_dmca_and_illegal/?st=j24nd4on&sh=86fd55ce}
\bibitem{Whitepaper} Whitepaper
\bibitem{libp2pissues} \url{https://www.infoq.com/presentations/data-ipfs-ipld}, 15min
\bibitem{ndn} \url{https://named-data.net/} 14.05.2017
\bibitem{xia} \url{https://www.cs.cmu.edu/~xia/} 14.05.2017
\bibitem{libp2pnoip} \url{https://github.com/libp2p/specs/blob/master/3-requirements.md} 
\bibitem{dht-provide} \url{https://github.com/ipfs/go-ipfs/issues/1396}
\bibitem{DNS} \url{https://news.ycombinator.com/item?id=10229481} 14.05.2017
\bibitem{ipfs-usage-web} \url{}
\bibitem{freenas} \url{http://www.freenas.org/blog/announcing-freenas-10-alpha/}
\bibitem{turkeyblock} \url{https://ipfs.io/blog/24-uncensorable-wikipedia/}
\bibitem{ether}
\bibitem{blockchain-data} \url{http://www.coindesk.com/ethereum-meets-zcash-why-ipfs-plans-a-multi-blockchain-browser/}
\bibitem{sia} \url{http://sia.tech/}  14.05.2017
\bibitem{Maidsafe} \url{https://maidsafe.net/} 14.05.2017


\end{thebibliography}


\printglossaries

\listoffigures
%https://github.com/multiformats/multihash/blob/master/hashtable.csv


\end{document}